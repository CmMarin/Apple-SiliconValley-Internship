from typing import Dict, Any, List, Optional, Union
import threading
import time
import logging
from enum import Enum

# Keep transformers imports
from transformers import pipeline
from app.nlp.extractor import extract_tasks

# Setup logger
logger = logging.getLogger(__name__)

class ModelState(str, Enum):
    NOT_LOADED = "not_loaded"
    LOADING = "loading"
    READY = "ready"
    ERROR = "error"

class AIModelService:
    """
    A service to manage AI model loading and inference with status tracking
    and fallback mechanisms.
    """
    
    def __init__(self):
        self._model = None
        self._state = ModelState.NOT_LOADED
        self._error = None
        self._lock = threading.Lock()
        self._load_thread = None
        self._model_path = "google/flan-t5-small"  # Default model
    
    def get_status(self) -> Dict[str, Any]:
        """Get the current status of the AI model"""
        # Track when we last logged a status check to reduce log spam
        old_state = self._state
        
        # Store status result
        status = {
            "state": self._state,
            "model": self._model_path if self._model else None,
            "error": str(self._error) if self._error else None,
            "loading_started": self._load_thread is not None and self._load_thread.is_alive()
        }
        
        # Only log status checks if it's been more than 30 seconds since last log
        # or if there's an error or state change
        current_time = time.time()
        should_log = (
            self._last_status_check is None or
            (current_time - self._last_status_check) > 30 or
            self._state == ModelState.ERROR or
            old_state != self._state
        )
        
        if hasattr(self, '_last_status_check') and should_log:
            logger.debug(f"Model status check: {status}")
            self._last_status_check = current_time
        elif not hasattr(self, '_last_status_check'):
            self._last_status_check = current_time
            
        return status
    
    def start_loading(self) -> None:
        """
        Begin loading the model in a background thread if not already loading
        """
        with self._lock:
            if self._state == ModelState.LOADING:
                # Already loading
                return
                
            if self._state == ModelState.READY:
                # Already loaded
                return
                
            # Start loading in background thread
            self._state = ModelState.LOADING
            self._error = None
            self._load_thread = threading.Thread(target=self._load_model)
            self._load_thread.daemon = True
            self._load_thread.start()
    
    def _load_model(self) -> None:
        """Internal method to load the model"""
        try:
            logger.info(f"Loading model {self._model_path}...")
            start_time = time.time()
            
            # Load the model
            self._model = pipeline(
                "text2text-generation",
                model=self._model_path,
                tokenizer=self._model_path,
                device=-1  # Use CPU
            )
            
            # Update state
            with self._lock:
                self._state = ModelState.READY
                
            elapsed = time.time() - start_time
            logger.info(f"Model loaded successfully in {elapsed:.2f} seconds")
            
        except Exception as e:
            # Handle errors
            logger.error(f"Error loading model: {e}")
            with self._lock:
                self._state = ModelState.ERROR
                self._error = e
    
    def process_text(self, text: str, options: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Process text input with fallback mechanisms
        
        Args:
            text: The input text to process
            options: Processing options (lang, forceJson, etc.)
            
        Returns:
            Dictionary with processing results and metadata
        """
        options = options or {}
        force_json = options.get("forceJson", True)
        
        # If model not ready, use fallback extractor
        if self._state != ModelState.READY:
            # Use regex-based extractor as fallback
            logger.info("Model not ready, using fallback extractor")
            tasks = extract_tasks(text)
            return {
                "tasks": tasks,
                "method": "regex_fallback",
                "model_state": self._state,
                "message": "Using regex fallback because AI model is not ready"
            }
        
        # Try AI model processing
        try:
            # Build the prompt for task extraction
            prompt = self._build_prompt(text)
            
            # Generate with model
            output = self._model(prompt, max_new_tokens=256, temperature=0.1, do_sample=False)
            content = output[0]["generated_text"] if isinstance(output, list) else str(output)
            
            # Parse and normalize the results
            parsed_tasks = self._parse_model_output(content, force_json)
            
            return {
                "tasks": parsed_tasks,
                "method": "ai_model",
                "model_state": self._state,
                "message": "Successfully processed with AI model"
            }
        except Exception as e:
            # If AI processing fails, fall back to regex extractor
            logger.error(f"Error during AI processing: {e}")
            tasks = extract_tasks(text)
            
            return {
                "tasks": tasks,
                "method": "regex_fallback_after_error",
                "model_state": self._state,
                "error": str(e),
                "message": "Used regex fallback after AI model error"
            }
    
    def _build_prompt(self, text: str) -> str:
        """Build a prompt for task extraction"""
        return (
            "You are an expert task extraction engine that can understand Romanian and English. Read the INPUT and produce a JSON array of tasks.\n"
            "Rules:\n"
            "- Language may be Romanian or English.\n"
            "- Output ONLY valid JSON (no markdown, no explanation).\n"
            "- Each item has keys exactly: task, time, category, deadline.\n"
            "- Use null for unknown fields.\n"
            "- Ignore greetings, filler, random characters, or single letters.\n"
            "- Do not split words into letters.\n"
            "- Extract tasks even when the wording is informal or conversational.\n"
            "- If there are no tasks, return [].\n\n"
            "Categories should be one of: Work, Family, Shopping, Health, Finance, Travel, Social, Study, Urgent, General.\n"
            "Categorize based on keywords like:\n"
            "- Work: job, office, meeting, project, report, email, presentation, client, boss, colleague, muncă, birou, întâlnire, proiect, etc.\n"
            "- Family: home, house, kids, children, parent, school, homework, clean, cook, dinner, familie, casă, copii, școală, curățenie, etc.\n"
            "- Shopping: buy, shop, store, groceries, market, mall, order, deliver, cumpăra, magazin, cumpărături, comandă, etc.\n"
            "- Health: doctor, appointment, medicine, workout, gym, fitness, dentist, hospital, medic, programare, medicament, etc.\n"
            "- Finance: pay, bill, invoice, money, bank, account, tax, payment, plăti, factură, bani, bancă, etc.\n"
            "- Travel: trip, travel, flight, airport, hotel, vacation, car, drive, bus, train, călătorie, zbor, vacanță, mașină, etc.\n"
            "- Social: party, event, birthday, celebration, friend, restaurant, concert, movie, petrecere, ziua de naștere, prieteni, etc.\n"
            "- Study: study, learn, course, class, lecture, exam, test, homework, studiu, învăța, curs, examen, etc.\n"
            "- Urgent: urgent, priority, important, critical, high, asap, immediately, urgent, prioritate, important, etc.\n\n"
            "Times should be extracted when present, in formats like 9:00, 9:00am, 9am, 9 PM, la 15:30, etc.\n"
            "Deadlines should be extracted when present, in formats like June 15, 15/06/2023, tomorrow, by Friday, maine, mâine, azi, astăzi, etc.\n\n"
            "Examples of Romanian tasks extraction:\n"
            "- \"trebuie maine sa ma duc la magazin\" → [{\"task\": \"ma duc la magazin\", \"time\": null, \"category\": \"Shopping\", \"deadline\": \"maine\"}]\n"
            "- \"programare la dentist joi la 14:30\" → [{\"task\": \"programare la dentist\", \"time\": \"14:30\", \"category\": \"Health\", \"deadline\": \"joi\"}]\n"
            "- \"să plătesc factura la lumină până vineri\" → [{\"task\": \"plătesc factura la lumină\", \"time\": null, \"category\": \"Finance\", \"deadline\": \"vineri\"}]\n\n"
            f"INPUT: {text}\n\n"
            "JSON:"
        )
    
    def _parse_model_output(self, output: str, force_json: bool = True) -> List[Dict[str, Any]]:
        """Parse and normalize model output with enhanced error handling"""
        import re
        import json
        
        logger.info(f"Raw model output: {output}")
        
        # Try to extract a JSON array from the output
        json_pattern = r"(\[.*?\])"
        match = re.search(json_pattern, output, re.DOTALL)
        
        # If not found, try a more lenient approach (look for any array)
        if not match:
            json_pattern = r"(\[[\s\S]*\])"
            match = re.search(json_pattern, output, re.DOTALL)
        
        # If still not found, check if the whole output is a valid JSON
        if not match and output.strip().startswith("[") and output.strip().endswith("]"):
            match = re.match(r"(\[[\s\S]*\])", output.strip())
        
        # If no valid JSON found and force_json is True, fall back to regex extraction
        if not match and force_json:
            logger.warning("No JSON found in model output, using fallback extraction")
            # Before falling back, try parsing the raw output one more time
            try:
                if output.strip():
                    data = json.loads(output.strip())
                    if isinstance(data, list):
                        match = True  # Signal that we have valid JSON
                    else:
                        return extract_tasks(output)
                else:
                    return extract_tasks(output)
            except json.JSONDecodeError:
                return extract_tasks(output)
            
        # If match found or we've managed to parse the whole output, process it
        if match or (output.strip().startswith("[") and output.strip().endswith("]")):
            try:
                # Try to parse the matched JSON string
                json_str = match.group(1) if match else output.strip()
                
                # Replace common issues in JSON parsing
                json_str = json_str.replace("'", '"')  # Replace single quotes with double quotes
                json_str = re.sub(r',(\s*[\]}])', r'\1', json_str)  # Remove trailing commas
                
                data = json.loads(json_str)
                
                # Handle empty array
                if len(data) == 0:
                    logger.warning("Model returned empty task array, falling back to regex extraction")
                    raw_tasks = extract_tasks(output)
                    
                    # If even regex can't extract tasks, try the input text
                    if not raw_tasks and hasattr(self, '_last_input') and self._last_input:
                        logger.warning("Both model and regex failed to extract tasks, trying input text directly")
                        return extract_tasks(self._last_input)
                    return raw_tasks
                
                # Normalize the task format
                tasks = []
                for item in data:
                    if not isinstance(item, dict):
                        logger.warning(f"Skipping non-dict item in parsed output: {item}")
                        continue
                        
                    task_text = str(item.get("task", "")).strip()
                    
                    # Skip if task is empty or too short
                    if not task_text or len(task_text) < 3:
                        continue
                        
                    # Skip if task is a single letter or common greeting
                    if re.fullmatch(r"[A-Za-z]", task_text) or task_text.lower() in {"hi", "hello", "salut", "hey"}:
                        continue
                        
                    # Add the normalized task
                    tasks.append({
                        "task": task_text,
                        "time": item.get("time") or None,
                        "category": item.get("category") or None,
                        "deadline": item.get("deadline") or None
                    })
                
                # If we still have no tasks, fall back
                if not tasks and force_json:
                    logger.warning("Model returned invalid tasks, falling back to regex extraction")
                    return extract_tasks(output)
                
                return tasks
            except json.JSONDecodeError as e:
                logger.error(f"Error parsing JSON from model output: {e}")
                if force_json:
                    return extract_tasks(output)
        
        # If we get here, either no match was found or JSON parsing failed
        if force_json:
            return extract_tasks(output)
        return []
        
    def process_text(self, text: str, options: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Process text input with fallback mechanisms
        
        Args:
            text: The input text to process
            options: Processing options (lang, forceJson, etc.)
            
        Returns:
            Dictionary with processing results and metadata
        """
        options = options or {}
        force_json = options.get("forceJson", True)
        
        # Store the input text for potential fallback
        self._last_input = text
        
        # If model not ready, use fallback extractor
        if self._state != ModelState.READY:
            # Use regex-based extractor as fallback
            logger.info("Model not ready, using fallback extractor")
            tasks = extract_tasks(text)
            return {
                "tasks": tasks,
                "method": "regex_fallback",
                "model_state": self._state,
                "message": "Using regex fallback because AI model is not ready"
            }
        
        # Try AI model processing
        try:
            # Build the prompt for task extraction
            prompt = self._build_prompt(text)
            
            # Generate with model
            output = self._model(prompt, max_new_tokens=256, temperature=0.1, do_sample=False)
            content = output[0]["generated_text"] if isinstance(output, list) else str(output)
            
            # Parse and normalize the results
            parsed_tasks = self._parse_model_output(content, force_json)
            
            # If AI model returned no tasks, fall back to regex extractor
            if not parsed_tasks:
                logger.warning("AI model returned no tasks, trying fallback extraction")
                tasks = extract_tasks(text)
                
                # Only use fallback if it found something
                if tasks:
                    return {
                        "tasks": tasks,
                        "method": "regex_fallback_after_ai_empty",
                        "model_state": self._state,
                        "message": "Used regex fallback after AI model returned no tasks"
                    }
            
            return {
                "tasks": parsed_tasks,
                "method": "ai_model",
                "model_state": self._state,
                "message": "Successfully processed with AI model"
            }
        except Exception as e:
            # If AI processing fails, fall back to regex extractor
            logger.error(f"Error during AI processing: {e}")
            tasks = extract_tasks(text)
            
            return {
                "tasks": tasks,
                "method": "regex_fallback_after_error",
                "model_state": self._state,
                "error": str(e),
                "message": "Used regex fallback after AI model error"
            }

# Create a global instance of the service
model_service = AIModelService()

# Start loading the model when the module is imported
model_service.start_loading()